## AVX-512 Instruction Groups
While AVX-512 is most visibly an extension of AVX and AVX2 to a 512 bit width, 27% of AVX-512 intrinsics are 128 or 256 bits wide. Beginning in Q3 2017, Skylake X-series (i7 and i9) and Xeon processors enabled support 3959 of the 5139 AVX-512 intrinsics defined by Intel. In Q3 2019, Ice Lake (Sunny Cove microarchitecture) expanded the set to 4130 intrinsics and, unofficially, Alder Lake (Golden Cove microarchitecture) to 5095 intrinsics in Q4 2021. Alder Lake appears to support 100% of intrinsics which are not obsolete.

| group   | what                          | instructions | intrinsics | Alder Lake | Sunny Cove              | Skylake       | Knights | VL intrinsics |
| ------- | ----------------------------- | ------------ | ---------- | ---------- | ----------------------- | ------------- | ------- | ------------- |
| F       | foundation                    |  389         | 1435       | (P-core)   | Rocket, Tiger, Ice Lake | X, Xeon 2017+ | all     |               |
| CD      | conflict detection            |    8         |   42       | (P-core)   | Rocket, Tiger, Ice Lake | X, Xeon 2017+ | all     |   28          |
| VL      | 128 and 256 bit widths        |  223         | 1208       | (P-core)   | Rocket, Tiger, Ice Lake | X, Xeon 2017+ |         | 1208          |
| DQ      | doubleword and quadword       |   87         |  399       | (P-core)   | Rocket, Tiger, Ice Lake | X, Xeon 2017+ |         |  176          |
| BW      | byte and word                 |  150         |  764       | (P-core)   | Rocket, Tiger, Ice Lake | X, Xeon 2017+ |         |  446          |
| BITALG  | population count expansion    |    5         |   24       | (P-core)   | Rocket, Tiger, Ice Lake |               |         |   16          |
| IFMA52  | big integer FMA               |    3         |   18       | (P-core)   | Rocket, Tiger, Ice Lake | (Cannon Lake) |         |   12          |
| VBMI    | vector byte manipulation      |    8         |   30       | (P-core)   | Rocket, Tiger, Ice Lake | (Cannon Lake) |         |   20          |
| VBMI2   | vector byte manipulation      |   21         |  150       | (P-core)   | Rocket, Tiger, Ice Lake |               |         |  100          |
| VNNI    | vector neural network         |    5         |   36       | (P-core)   | Rocket, Tiger, Ice Lake | Cascade Lake  |         |   24          |
| VPOPCNT | population count              |    3         |   18       | (P-core)   | Rocket, Tiger, Ice Lake |               | Mill    |   12          |
| BF16    | half precision                |    5         |   27       | (P-core)   |                         | Cooper Lake   |         |   18          |
| FP16    | half precision                |   96         |  938       | (P-core)   |                         |               |         |  600          |
| VP2INTERSECT | vector pair to mask pair |    2         |    6       | (P-core)   | Tiger Lake              |               |         |    4          |
| 4FMAPS  | single precision 4x1 FMA      |    4         |   12       |            |                         |               | Mill    |               |
| 4NNIW   | vector neural network         |    2         |    6       |            |                         |               | Mill    |               |
| ER      | exponential and reciprocal    |   12         |   60       |            |                         |               | all     |               |
| PF      | prefetch                      |    9         |   20       |            |                         |               | all     |               |
| total   |                               | 1031         | 5193       |            |                         |               |         | 2060          |

The table above derives from the [Intel Intrinsics Guide](https://software.intel.com/sites/landingpage/IntrinsicsGuide/), [Intel ARK](https://ark.intel.com/content/www/us/en/ark/search/featurefilter.html?productType=873&1_Filter-InstructionSetExtensions=3533), and [Intel 64 and IA-32 Architectures Software Developer's Manuals](https://software.intel.com/content/www/us/en/develop/articles/intel-sdm.html). It will therefore be inaccurate if Intel's information is inaccurate or if transcription errors were made. In particular, sections 15.2-4 of the architecture manual, volume 1, require software check for F before using other groups. However, the Intrinsics Guide does not indicate corresponding dependencies for many groups. The spreadsheet in this repo lists each group's instructions and intrinsics.

## AVX-512 Availablity
| release dates      | processor       | laptop, desktop | workstation, server               | performance data |
| ------------------ | --------------- | --------------- | --------------------------------- | ---------------- |
| TBD                | Sapphire Rapids |                 | TBD                               |                  |
| Q4 2021 to TBD     | Alder Lake      | unofficial      |                                   |                  |
| Q1 2021 to Q3 2021 | Rocket Lake     | i5, i7, i9      | E, W                              | [phoronix](https://www.phoronix.com/scan.php?page=article&item=rocket-lake-avx512&num=1) |
| Q3 2020 to Q3 2021 | Tiger Lake      | i3, i5, i7, i9  | W                                 |                  |
| Q2 2020            | Cooper Lake     |                 | Gold, Platinum                    |                  |
| Q3 2019 to Q2 2021 | Ice Lake        | i3, i5, i7      | W, Silver, Gold, Platinum         | [Microway](https://www.microway.com/knowledge-center-articles/detailed-specifications-of-the-ice-lake-sp-intel-xeon-processor-scalable-family-cpus/) |
| Q2 2019 to Q1 2020 | Cascade Lake    | i9              | W, Bronze, Silver, Gold, Platinum | [Microway](https://www.microway.com/knowledge-center-articles/detailed-specifications-of-the-cascade-lake-sp-intel-xeon-processor-scalable-family-cpus/) |
| Q3 2018            | Cannon Lake     | i3-8121U        |                                   |                  |
| Q3 2017 to Q2 2018 | Skylake         | X-Series i7, i9 | W, Bronze, Silver, Gold, Platinum | [AnandTech](https://www.anandtech.com/show/11544/intel-skylake-ep-vs-amd-epyc-7000-cpu-battle-of-the-decade/8) |
| Q4 2017            | Knights Mill    |                 | Phi                               |                  |
| Q2 2016 to Q4 2016 | Knights Landing |                 | Phi                               |                  |

Before 2020, AVX-512 was available mainly on Cascade Lake and Skylake Xeons. While Cooper Lake and Tiger Lake provide AVX-512, as of February 2022 AVX-512 is perhaps most readily available on 11<sup>th</sup> generation i5, i7, and i9 parts (Rocket Lake). Ice Lake and Comet Lake are both marketed as 10<sup>th</sup> generation processors but Ice Lake volume was limited and AVX-512 is not available on Comet Lake processors. Similarly, Cannon Lake i3s (Palm Cove microarchitecture) are rare and the Kaby and Coffee Lake Skylake iterations lack AVX-512. AMD does not currently implement AVX-512 but may do so in Zen 4.

Intel indicated AVX-512 would be disabled on Alder Lake CPUs, implying 12<sup>th</sup> generation AVX-512 availability would be limited to Sapphire Rapids Xeons. However, since Alder Lake P-cores (Golden Cove microarchitecture) can execute AVX-512 instructions when E-cores are disabled ([anandtech](https://www.anandtech.com/show/17047/the-intel-12th-gen-core-i912900k-review-hybrid-performance-brings-hybrid-complexity/2), [igorslab](https://www.igorslab.de/en/intel-deactivated-avx-512-on-alder-lake-but-fully-questionable-interpretation-of-efficiency-news-editorial/)) it appears more accurate to state Intel declines to support AVX-512 on Alder Lake.

This table is obtained from [Intel ARK](https://ark.intel.com/content/www/us/en/ark/search/featurefilter.html?productType=873&1_Filter-InstructionSetExtensions=3533) release dates. Specfic processors are listed in this repo's spreadsheet. No Pentium or Celeron processor has yet supported AVX-512.

## Instruction Group Dependencies and CPUID Flags
The 18 AVX-512 instruction groups have individual CPUID flags and, in principle, an instruction could require an arbitrary number of groups be present. In practice, this is rarely a concern as the only dependencies which exist are on groups F and VL. Since VL is not present independent of F on any of Intel's processors, its dependency is always satisfied. Similarly, all processors with instruction groups containing VL dependent intrinsics implement VL. There are also 324 128 or 256 bit intrinsics for which the Intrinsics Guide does not indicate a VL requirement. These are primarily ss and sd floating point intrinsics which modify only the low 32 or 64 bits of a register.

It appears reasonable to assume all Skylake and later processors with AVX-512 support will implement at least the F, CD, VL, DQ, and BW groups. While Intel could choose otherwise, doing would complicate hardware implementation, compiler support, and software compatibility. It is also plausible the BITALG, IFMA52, VBMI, VBMI2, VNNI, and VPOPCNT groups will be consistently implemented from Ice Lake forward for the same reasons. However, Intel does not seem to have made any official statement regarding future compatibility. Similarly, AMD does not appear to have indicated what groups a Zen 4 implementation might support. However, an AMD implementation seems likely to be broadly compatible with Intel's.

Since AVX-512 is restricted to 512 bit widths on the now discontinued Xeon Phis, these processors do not implement the vector length extensions of the VL group. They therefore lack dependencies between groups and share only the F and CD groups with Skylake and later implementions. The 4NNIW group appears to be replaced by VNNI and the PF group by architectural changes.

## Performance Considerations
The Skylake-Cascade Lake and Sunny Cove-Cypress Cove microarchitectures provide SIMD computation on ports 0, 1, and 5. It appears AVX-512 operation is obtained by combining ports 0 and 1 and, when two AVX-512 instructions per clock are supported, possibly by combining ports 5 and 6. Due to downclocking when [instructions and threads cross thermal license boundaries](https://travisdowns.github.io/blog/2020/08/19/icl-avx512-freq.html) ([Gottshlag and Bellosa 2019](https://os.itec.kit.edu/downloads/2019_mathias_gottschlag_sfma_paper.pdf)), use of AVX-512 may sometimes be slower than implementing the same workload with AVX and AVX2 ([Franek Korta](https://extensa.tech/blog/avx-throttling-part1/)). Use of AVX-512 also decreases instruction rate from 3x256 per clock to 2x512, which may not be offset by wider loads and stores (see [Agner Fog](https://www.agner.org/optimize/blog/read.php?i=628#415) or [Stackoverflow](https://stackoverflow.com/questions/15655835/flops-per-cycle-for-sandy-bridge-and-haswell-sse2-avx-avx2) for examples at 256 bit width), zmm register availability, or use of efficiency instructions such as vgetmantp or vgetexpp. AVX-512 may be similarly disadvantageous on processors restricted to 1x512, which includes bronze, silver, some 5000 series gold, and D Skylake Xeons as well as Knights processors. As of February 2022, how the addition of port 10 and other [microarchitectural changes in Golden Cove](https://anandtech.com/show/16881/a-deep-dive-into-intels-alder-lake-microarchitectures/3) may alter these considerations is uncertain.

In general, compute kernel throughput is sensitive to instruction level parallelism available within the kernel's inner loop and a processor's FMA, ALU, shift, floating point divide, shuffle, and load and store capabilities. For Ice Lake, Intel indicates one AVX-512 FMA and shuffle and two AVX-512 ALUs (*e.g.* [Cutress 2019](https://www.anandtech.com/show/14514/examining-intels-ice-lake-microarchitecture-and-sunny-cove/12)). Some kernels may therefore execute more quickly at 256 bit width due to accessing two FMA and shuffle units rather than one. Additionally, using the 1400 128 and 256 bit AVX-512VL intrinsics to reduce register spilling (from 32 zmm instead of 16 ymm registers) may be more efficient than the width of 512 bit intrinsics. In some cases 128 bit kernels can also be faster than 256 or 512 bit ones due to computational details of the kernel such as dependencies between AVX lanes.

It's therefore useful to profile SIMD implementations at 128, 256, and 512 bit widths across processors and amounts of computation to be performed. In performance code segments, this can result in width dispatching being controlled by loop content or iteration count rather than making use of the widest instructions supported by the processor.