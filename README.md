## Summary
While AVX-512 is most visibly an extension of AVX and AVX2 to a 512 bit width, 57% of AVX-512 intrinsics are 128 or 256 bits wide. Skylake architecture CPUs with AVX-512 all support at least 3959 of the 4255 AVX-512 intrinsics defined by Intel. Ice Lake expands the minimum set to 4130 intrinsics, 100% of the intrinsics available on processors currently in production.

| group   | what                          | instructions | intrinsics | Skylake      | Sunny Cove | Knights | require F | require VL |
| ------- | ----------------------------- | ------------ | ---------- | ------------ | ---------- | ------- | --------- | ---------- |
| F       | foundation                    | 389          | 1435       | X, Xeon      | Ice Lake   | all     |           |            |
| CD      | conflict detection            |   8          |   42       | X, Xeon      | Ice Lake   | all     |           |  28        |
| VL      | 128 and 256 bit widths        | 223          | 1208       | X, Xeon      | Ice Lake   |         | 1208      |            |
| DQ      | doubleword and quadword       |  87          |  399       | X, Xeon      | Ice Lake   |         |    ?      | 176        |
| BW      | byte and word                 | 150          |  764       | X, Xeon      | Ice Lake   |         |    ?      | 446        |
| BITALG  | population count expansion    |   5          |   24       |              | Ice Lake   |         |    ?      |  16        |
| IFMA52  | big integer FMA               |   3          |   18       | Cannon Lake  | Ice Lake   |         |    ?      |  12        |
| VBMI    | vector byte manipulation      |   8          |   30       | Cannon Lake  | Ice Lake   |         |    ?      |  20        |
| VBMI2   | vector byte manipulation      |  21          |  150       |              | Ice Lake   |         |    ?      | 100        |
| VNNI    | vector neural network         |   5          |   36       | Cascade Lake | Ice Lake   |         |    ?      |  24        |
| VPOPCNT | population count              |   3          |   18       |              | Ice Lake   | Mill    |    ?      |  12        |
| BF16    | half precision                |   5          |   27       |              |            |         |    9      |  18        |
| VP2INTERSECT | vector pair to mask pair |   2          |    6       |              |            |         |    2      |   4        |
| 4FMAPS  | single precision 4x1 FMA      |   4          |   12       |              |            | Mill    |    ?      |            |
| 4NNIW   | vector neural network         |   2          |    6       |              |            | Mill    |    ?      |            |
| ER      | exponential and reciprocal    |  12          |   60       |              |            | all     |    ?      |            |
| PF      | prefetch                      |   9          |   20       |              |            | all     |    ?      |            |
| total   |                               | 936          | 4255       |              |            |         | 1219?     | 856        |

Prior to i3, i5, and i7 Ice Lakes, AVX-512 was available mainly on Skylake and Cascade Lake i9s and Xeons. Tiger Lake CPUs and Cooper Lake Xeons are expected to have AVX-512 but Intel is not shipping these CPUs as of May 2020. AVX-512 was first available on the now discontinued Xeon Phis (Knights Landing and Knights Mill), though their support is limited to compared to Skylake and later implementations. The i3-8121U, the only Cannon Lake processor, shipped in low volume. AMD does not currently implement AVX-512.

The table above derives from the [Intel Intrinsics Guide](https://software.intel.com/sites/landingpage/IntrinsicsGuide/), [Intel ARK](https://ark.intel.com/content/www/us/en/ark/search/featurefilter.html?productType=873&1_Filter-InstructionSetExtensions=3533), and [Intel 64 and IA-32 Architectures Software Developer's Manuals](https://software.intel.com/content/www/us/en/develop/articles/intel-sdm.html). It will therefore be inaccurate if Intel's information is inaccurate or if transcription errors were made. In particular, sections 15.2-4 of the architecture manual, volume 1, require software check for F before using other groups. However,  the Intrinsics Guide does not indicate corresponding dependencies for many groups.

## Instruction Group Dependencies and CPUID Flags
The 17 AVX-512 instructions group have individual CPUID flags and, in principle, an instruction could require an arbitrary number of groups be present. In practice, this is rarely a concern as the only dependencies which exist are on groups F and VL. Since VL is not present independent of F on any of Intel's processors, its dependency is always satisfied. Similarly, all processors with instruction groups containing VL dependent intrinsics implement VL. There are also 324 128 or 256 bit intrinsics for which the Intrinsics Guide does not indicate a VL requirement. These are primarily ss and sd floating point intrinsics which modify only the low 32 or 64 bits of a register.

It appears reasonable to assume Sunny Cove processors will implement at least the F, CD, VL, DQ, and BW groups. While Intel could choose otherwise, doing would complicates hardware implementation, compiler support, and software compatibility. It is also plausible Sunny Cove will consistently implement the BITALG, IFMA52, VBMI, VBMI2, VNNI, and VPOPCNT groups found on Ice Lake. However, Intel does seem to have made any official statement regarding this. Similarly, AMD hasn't indicated what groups an AVX-512 implementation might support. However, an AMD implementation would presumably be subject to the same F, CD, VL, DQ, and BW motivation as Intel is.

Since AVX-512 is restricted to 512 bit widths on the now discontinued Xeon Phis, these processors do not implement the vector length extensions of the VL group. They therefore lack dependencies between groups and share only the F and CD groups with Skylake and later implementions. The 4NNIW group appears to be replaced by VNNI and the PF group by architectural changes.

## Performance Considerations
Bronze, silver, some 5000 series gold, and D Xeons have one AVX-512 FMA per core, as do Knights processors. They can therefore issue at most one 512 bit instruction per clock. Platinum, W, and most gold Xeons—plus Core X processors—have two 512 bit FMAs for two instructions per clock. The Skylake, Cascade Lake, and Sunny Cove microarchitectures all support SIMD computation on ports 0, 1, and 5. It appears AVX-512 operation is obtained by combining ports 0 and 1 and, where two AVX-512 instructions per clock are supported, possibly by combining ports 5 and 6. In addition to the downclocking and voltage regulator step up latencies associated with operations wider than 128 bits, use of 512 may sometimes be slower than 256 for the same workload. This occurs because the instruction rate decrease from 3x256 per clock to 1-2x512 may not be offset by wider loads and stores ([Fog 2015](https://www.agner.org/optimize/blog/read.php?i=628#415), [Stackoverflow](https://stackoverflow.com/questions/15655835/flops-per-cycle-for-sandy-bridge-and-haswell-sse2-avx-avx2)).

In general, compute kernel throughput is sensitive to instruction level parallelism available within the computations required and processor's FMA, ALU, shift, floating point divide, shuffle, and load and store capabilities. For Ice Lake, Intel indicates one AVX-512 FMA and shuffle and two AVX-512 ALUs (*e.g.* [Cutress 2019](https://www.anandtech.com/show/14514/examining-intels-ice-lake-microarchitecture-and-sunny-cove/12)). Some kernels may therefore execute more quickly at 256 bit width due to accessing two FMA and shuffle units rather than one. Additionally, in some cases 128 bit kernels can be faster than 256 or 512 bit ones due to access to higher turbo and base clocks or computational details within a kernel.

It's therefore useful to profile kernel implementations at 128, 256, and 512 bit widths across processors and potentially also the amount of computation to be performed. In performance sensitive applications, this can result in width dispatching as well as more traditional CPU dispatching. Broadly, this suggests use of the 2400 128 and 256 bit AVX-512 intrinsics is likely to be at least as important than the 1800 512 bit ones.
